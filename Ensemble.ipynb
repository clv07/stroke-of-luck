{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPMgGjLg8lSvA/H2Ugt9d88",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clv07/stroke-of-luck/blob/Data-import/Ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOJxQEz83iVy"
      },
      "outputs": [],
      "source": [
        "# LOAD IN DATA\n",
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv('positive.csv', na_values=['NULL'])\n",
        "\n",
        "df2 = pd.read_csv('negative.csv', na_values=['NULL'])\n",
        "\n",
        "df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "df['AcquisitionDateTime_DT'] = pd.to_datetime(df['AcquisitionDateTime_DT'])\n",
        "\n",
        "#print(df.head())\n",
        "#print(df.info())\n",
        "#print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GET MODEL TO WORK IN COLAB W/ GPU (GO TO EDIT -> NOTEBOOK SETTINGS -> GPU)\n",
        "!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd"
      ],
      "metadata": {
        "id": "lBgWrcwH7GJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "RBggYsos3sG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "y = df[\"MI_Phys\"]\n",
        "\n",
        "X = df.drop(columns=[\"PatientID\", \"12SL_Codes\", \"Phys_Codes\", \"TestID\", \"Source\",\n",
        "                     \"Gender\", \"PatientAge\", \"AcquisitionDateTime_DT\", \"MI_Phys\", \"POffset\", \"PAxis\", \"POnset\"])\n",
        "X = X.loc[:, ~X.columns.str.contains('P_')]\n",
        "X = X.loc[:, ~X.columns.str.contains('Full')]\n",
        "X = X.loc[:, ~X.columns.str.contains('Rate')]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Save the original algorithm's prediction for test set before dropping it\n",
        "y_12SL = X_test[\"MI_12SL\"]\n",
        "\n",
        "# Split data based on MI_12SL classification\n",
        "X_train_pos = X_train[X_train[\"MI_12SL\"] == 1].drop(columns=[\"MI_12SL\"])\n",
        "X_train_neg = X_train[X_train[\"MI_12SL\"] == 0].drop(columns=[\"MI_12SL\"])\n",
        "X_test_pos = X_test[X_test[\"MI_12SL\"] == 1].drop(columns=[\"MI_12SL\"])\n",
        "X_test_neg = X_test[X_test[\"MI_12SL\"] == 0].drop(columns=[\"MI_12SL\"])\n",
        "\n",
        "# Ensure y labels match the correct samples\n",
        "y_train_pos = y_train.loc[X_train_pos.index]  # True positives or false positives\n",
        "y_train_neg = y_train.loc[X_train_neg.index]  # True negatives or false negatives\n",
        "y_test_pos = y_test.loc[X_test_pos.index]\n",
        "y_test_neg = y_test.loc[X_test_neg.index]\n",
        "\n",
        "X_train = X_train.drop(columns=[\"MI_12SL\"])\n",
        "X_test = X_test.drop(columns=[\"MI_12SL\"])\n",
        "\n",
        "# Extract MI_12SL predictions\n",
        "y_12SL_pos = y_12SL.loc[X_test_pos.index]  # Original classifier's labels\n",
        "y_12SL_neg = y_12SL.loc[X_test_neg.index]"
      ],
      "metadata": {
        "id": "XGCWyyMs3ysH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Positive Model\n",
        "lgb_params = {\n",
        "    'objective': 'binary',\n",
        "    'boosting_type': 'dart',\n",
        "    'colsample_bytree': 0.9889,\n",
        "    'n_estimators': 1000,\n",
        "    'learning_rate': 0.0807,\n",
        "    'random_state': 42,\n",
        "    'verbose': -1,\n",
        "    'num_leaves': 106,\n",
        "    'min_child_weight': 1,\n",
        "    'max_depth' : 7,\n",
        "    'reg_alpha' : 0.7909,\n",
        "    'reg_lambda' : 0.61348,\n",
        "    'subsample' : 0.903,\n",
        "    # 'metric': 'auc',\n",
        "    'scale_pos_weight': 3.537,\n",
        "    'device': 'gpu',\n",
        "    }\n",
        "model_pos = (lgb.LGBMClassifier(**lgb_params))\n",
        "model_pos.fit(X_train_pos, y_train_pos)\n",
        "y_pred_pos = model_pos.predict(X_test_pos)\n",
        "score = f1_score(y_test_pos, y_pred_pos, average='micro')\n",
        "print(\"Final F1 score: \", score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdrH_8w45HCf",
        "outputId": "93057558-ff19-4f20-fd48-5aee47c82200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final F1 score:  0.7859021567596002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add predictions as a new column to the test set\n",
        "X_test_pos_with_preds = X_test_pos.copy()\n",
        "X_test_pos_with_preds[\"MI_Predicted\"] = y_pred_pos\n",
        "\n",
        "# Get original data rows from `df` that correspond to the same indices as X_test_pos\n",
        "df_test_pos_original = df.loc[X_test_pos.index]\n",
        "\n",
        "# Join predictions back to the original dataset\n",
        "df_with_predictions = df_test_pos_original.copy()\n",
        "df_with_predictions[\"MI_Predicted\"] = y_pred_pos\n",
        "\n",
        "# Separate into positive and negative predictions\n",
        "df_mi_detected = df_with_predictions[df_with_predictions[\"MI_Predicted\"] == 1]\n",
        "df_no_mi_detected = df_with_predictions[df_with_predictions[\"MI_Predicted\"] == 0]"
      ],
      "metadata": {
        "id": "vDzIKUJU8rI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Negative Model\n",
        "lgb_params = {\n",
        "    'objective': 'binary',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'n_estimators': 200,\n",
        "    'learning_rate': 0.1,\n",
        "    'random_state': 42,\n",
        "    'verbose': -1,\n",
        "    'num_leaves': 127,\n",
        "    'scale_pos_weight': 10,\n",
        "    'device': 'gpu',\n",
        "    }\n",
        "model_neg = (lgb.LGBMClassifier(**lgb_params))\n",
        "model_neg.fit(X_train_neg, y_train_neg)\n",
        "y_pred_neg = model_neg.predict(X_test_neg)\n",
        "score = f1_score(y_test_neg, y_pred_neg, average='micro')\n",
        "print(\"Final F1 score: \", score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oovO_QVX5vmm",
        "outputId": "2630701e-2e62-41d8-a892-36f98b276d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final F1 score:  0.9538450195384502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add predictions to the test set\n",
        "X_test_neg_with_preds = X_test_neg.copy()\n",
        "X_test_neg_with_preds[\"MI_Predicted\"] = y_pred_neg\n",
        "\n",
        "# Get corresponding original rows from df\n",
        "df_test_neg_original = df.loc[X_test_neg.index]\n",
        "\n",
        "# Join predictions back to the original dataset\n",
        "df_with_predictions_neg = df_test_neg_original.copy()\n",
        "df_with_predictions_neg[\"MI_Predicted\"] = y_pred_neg\n",
        "\n",
        "# Separate based on prediction outcome\n",
        "df_mi_detected_neg = df_with_predictions_neg[df_with_predictions_neg[\"MI_Predicted\"] == 1]\n",
        "df_no_mi_detected_neg = df_with_predictions_neg[df_with_predictions_neg[\"MI_Predicted\"] == 0]"
      ],
      "metadata": {
        "id": "dCZHuMGJ8mkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine the two datasets\n",
        "df_combined_no_mi = pd.concat([df_no_mi_detected, df_no_mi_detected_neg], ignore_index=True)\n",
        "\n",
        "#Drop any prediction columns or non-feature columns\n",
        "df_combined_no_mi = df_combined_no_mi.drop(columns=[\"MI_Predicted\"], errors=\"ignore\")\n",
        "\n",
        "#Prepare features for prediction\n",
        "X_combined = df_combined_no_mi.drop(columns=[\"PatientID\", \"12SL_Codes\", \"Phys_Codes\", \"TestID\", \"Source\",\n",
        "                                             \"Gender\", \"PatientAge\", \"AcquisitionDateTime_DT\", \"MI_Phys\",\n",
        "                                             \"POffset\", \"PAxis\", \"POnset\"], errors='ignore')\n",
        "\n",
        "X_combined = X_combined.loc[:, ~X_combined.columns.str.contains('P_')]\n",
        "X_combined = X_combined.loc[:, ~X_combined.columns.str.contains('Full')]\n",
        "X_combined = X_combined.loc[:, ~X_combined.columns.str.contains('Rate')]\n",
        "X_combined = X_combined.drop(columns=[\"MI_12SL\"], errors='ignore')  # also drop MI_12SL if it's still there\n",
        "\n",
        "# Confirm shape matches the model's training input\n",
        "assert X_combined.shape[1] == model_neg.n_features_in_, f\"Expected {model_neg.n_features_in_} features, got {X_combined.shape[1]}\"\n",
        "\n",
        "# Step 4: Predict again\n",
        "y_combined_pred = model_neg.predict(X_combined)\n",
        "\n",
        "# Step 5: Reattach predictions\n",
        "df_combined_no_mi[\"MI_Predicted_Again\"] = y_combined_pred\n",
        "\n",
        "# Separate based on predictions\n",
        "df_still_no_mi = df_combined_no_mi[df_combined_no_mi[\"MI_Predicted_Again\"] == 0]\n",
        "df_new_mi_detected = df_combined_no_mi[df_combined_no_mi[\"MI_Predicted_Again\"] == 1]\n"
      ],
      "metadata": {
        "id": "RUHYACuz9FRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicate prediction columns if they exist\n",
        "df_mi_detected = df_mi_detected.drop(columns=[\"MI_Predicted\"], errors=\"ignore\")\n",
        "df_mi_detected_neg = df_mi_detected_neg.drop(columns=[\"MI_Predicted\"], errors=\"ignore\")\n",
        "df_new_mi_detected = df_new_mi_detected.drop(columns=[\"MI_Predicted_Again\"], errors=\"ignore\")\n",
        "\n",
        "# Combine all MI-detected datasets\n",
        "df_all_mi_detected = pd.concat(\n",
        "    [df_mi_detected, df_mi_detected_neg, df_new_mi_detected],\n",
        "    ignore_index=True\n",
        ")\n",
        "\n",
        "# drop duplicates by PatientID\n",
        "df_all_mi_detected = df_all_mi_detected.drop_duplicates(subset=[\"PatientID\"])"
      ],
      "metadata": {
        "id": "LxEbsiid97z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tag predictions based on ground truth\n",
        "df_all_mi_detected[\"Prediction\"] = \"Positive\"\n",
        "df_still_no_mi[\"Prediction\"] = \"Negative\"\n",
        "\n",
        "#Combine both datasets for evaluation\n",
        "df_eval = pd.concat([df_all_mi_detected, df_still_no_mi], ignore_index=True)\n",
        "\n",
        "#Classify each row based on actual vs. predicted\n",
        "def classify_row(row):\n",
        "    if row[\"MI_Phys\"] == 1 and row[\"Prediction\"] == \"Positive\":\n",
        "        return \"True Positive\"\n",
        "    elif row[\"MI_Phys\"] == 0 and row[\"Prediction\"] == \"Positive\":\n",
        "        return \"False Positive\"\n",
        "    elif row[\"MI_Phys\"] == 0 and row[\"Prediction\"] == \"Negative\":\n",
        "        return \"True Negative\"\n",
        "    elif row[\"MI_Phys\"] == 1 and row[\"Prediction\"] == \"Negative\":\n",
        "        return \"False Negative\"\n",
        "    else:\n",
        "        return \"Unknown\"\n",
        "\n",
        "df_eval[\"PredictionType\"] = df_eval.apply(classify_row, axis=1)\n",
        "\n",
        "#Count results\n",
        "summary = df_eval[\"PredictionType\"].value_counts()\n",
        "print(\"Performance Summary:\")\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPX1HvtG_e0p",
        "outputId": "7afa220b-cd60-4c15-f7ac-157fae04c637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-b1b13378ab88>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_still_no_mi[\"Prediction\"] = \"Negative\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance Summary:\n",
            "PredictionType\n",
            "True Negative     13399\n",
            "True Positive      1007\n",
            "False Negative      587\n",
            "False Positive      471\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map prediction types to binary labels for evaluation\n",
        "df_eval[\"MI_Predicted_Final\"] = df_eval[\"PredictionType\"].map({\n",
        "    \"True Positive\": 1,\n",
        "    \"False Positive\": 1,\n",
        "    \"True Negative\": 0,\n",
        "    \"False Negative\": 0\n",
        "})\n",
        "\n",
        "y_true = df_eval[\"MI_Phys\"]\n",
        "y_pred = df_eval[\"MI_Predicted_Final\"]\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"F1 Score:\", f1_score(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX9PEO2jAh_i",
        "outputId": "e6555cca-d598-4571-c571-d6b85e0fe961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[13399   471]\n",
            " [  587  1007]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96     13870\n",
            "           1       0.68      0.63      0.66      1594\n",
            "\n",
            "    accuracy                           0.93     15464\n",
            "   macro avg       0.82      0.80      0.81     15464\n",
            "weighted avg       0.93      0.93      0.93     15464\n",
            "\n",
            "Accuracy: 0.931583031557165\n",
            "F1 Score: 0.6555989583333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensemble Layer 2\n",
        "# Localization Model: Detects MI region based on where in the heart it occurred\n",
        "# Input: Set of Patients who are positive for MI\n",
        "# Model: LightGBM classifier - acute or non-acute"
      ],
      "metadata": {
        "id": "ew9CqosTeRBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing essential libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "xbp10Qhnfsd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in data\n",
        "import pandas as pd\n",
        "\n",
        "df3 = pd.read_csv('positive_with_threat.csv', na_values=['NULL'])\n",
        "\n",
        "df3['AcquisitionDateTime_DT'] = pd.to_datetime(df['AcquisitionDateTime_DT'])\n"
      ],
      "metadata": {
        "id": "aVujgc8mfvda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i38ZI55ysc4j",
        "outputId": "9e0017b3-3070-4e82-bfee-d0d99ef6909c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
        "import lightgbm as lgb\n",
        "import optuna\n",
        "\n",
        "# Prepare features and labels\n",
        "y = df3[\"Threat\"]\n",
        "\n",
        "X = df3.drop(columns=[\n",
        "    \"PatientID\", \"12SL_Codes\", \"Phys_Codes\", \"TestID\", \"Source\",\n",
        "    \"Gender\", \"PatientAge\", \"AcquisitionDateTime_DT\", \"MI_Phys\",\n",
        "    \"POffset\", \"PAxis\", \"POnset\", \"Threat\"\n",
        "])\n",
        "X = X.loc[:, ~X.columns.str.contains(\"P_\")]\n",
        "X = X.fillna(0)\n",
        "\n",
        "# Standardization + PCA\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "pca = PCA(n_components=0.90, svd_solver='full')\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Train/validation split for tuning\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_pca, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Optuna objective function\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'binary',\n",
        "        'boosting_type': 'dart',\n",
        "        'metric': 'binary_logloss',\n",
        "        'verbosity': -1,\n",
        "        'random_state': 42,\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 31, 256),\n",
        "        'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
        "        'min_child_weight': trial.suggest_float('min_child_weight', 1e-3, 10.0, log=True),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 2.0),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 2.0),\n",
        "        'scale_pos_weight': 50.0  # based on your dataset imbalance\n",
        "    }\n",
        "\n",
        "    model = lgb.LGBMClassifier(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_valid)\n",
        "    return f1_score(y_valid, preds)\n",
        "\n",
        "# Run Optuna study\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)  # You can increase n_trials for deeper tuning\n",
        "\n",
        "# Report best results\n",
        "print(\"Best trial:\")\n",
        "print(study.best_trial)\n",
        "\n",
        "# Train final model with best params\n",
        "best_params = study.best_params\n",
        "best_params.update({\n",
        "    'objective': 'binary',\n",
        "    'boosting_type': 'dart',\n",
        "    'verbosity': -1,\n",
        "    'random_state': 42,\n",
        "    'scale_pos_weight': 50.0\n",
        "})\n",
        "\n",
        "final_model = lgb.LGBMClassifier(**best_params)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = final_model.predict(X_valid)\n",
        "\n",
        "print(\"\\nF1 Score:\", f1_score(y_valid, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_valid, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_valid, y_pred))\n",
        "\n",
        "# Optional: Show sample predictions\n",
        "results_df = pd.DataFrame({\n",
        "    \"Actual\": y_valid.values,\n",
        "    \"Predicted\": y_pred\n",
        "})\n",
        "print(results_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mv-njiUl8u3",
        "outputId": "643ab5bd-311a-4953-c64b-ae94cdf2d153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-24 21:26:42,136] A new study created in memory with name: no-name-ee3bf32c-cc36-482d-b990-94252181ad94\n",
            "[I 2025-04-24 21:26:45,229] Trial 0 finished with value: 0.3076923076923077 and parameters: {'learning_rate': 0.2057236569001665, 'num_leaves': 164, 'max_depth': 14, 'min_child_weight': 0.05705586231110782, 'subsample': 0.6806608026514656, 'colsample_bytree': 0.9797720020909362, 'reg_alpha': 0.6544003200646291, 'reg_lambda': 0.5325954189712003}. Best is trial 0 with value: 0.3076923076923077.\n",
            "[I 2025-04-24 21:26:48,415] Trial 1 finished with value: 0.34108527131782945 and parameters: {'learning_rate': 0.16490459438202168, 'num_leaves': 114, 'max_depth': 14, 'min_child_weight': 0.0506086168861971, 'subsample': 0.7292794841739291, 'colsample_bytree': 0.8042568169802898, 'reg_alpha': 1.775616106731585, 'reg_lambda': 0.41738457806593354}. Best is trial 1 with value: 0.34108527131782945.\n",
            "[I 2025-04-24 21:26:49,294] Trial 2 finished with value: 0.3424657534246575 and parameters: {'learning_rate': 0.1816708376072348, 'num_leaves': 93, 'max_depth': 5, 'min_child_weight': 0.005569757059934514, 'subsample': 0.8842914431581839, 'colsample_bytree': 0.5540019501646409, 'reg_alpha': 0.8602169491063745, 'reg_lambda': 0.16666324444337133}. Best is trial 2 with value: 0.3424657534246575.\n",
            "[I 2025-04-24 21:26:51,592] Trial 3 finished with value: 0.3115942028985507 and parameters: {'learning_rate': 0.0470023812905936, 'num_leaves': 91, 'max_depth': 9, 'min_child_weight': 2.177986831970507, 'subsample': 0.5607965910313233, 'colsample_bytree': 0.9802763031703075, 'reg_alpha': 1.5326192137168029, 'reg_lambda': 0.9368437857708902}. Best is trial 2 with value: 0.3424657534246575.\n",
            "[I 2025-04-24 21:26:53,786] Trial 4 finished with value: 0.3076923076923077 and parameters: {'learning_rate': 0.2503693931934388, 'num_leaves': 177, 'max_depth': 12, 'min_child_weight': 0.0014659932547737994, 'subsample': 0.9996910768371713, 'colsample_bytree': 0.9192192605257048, 'reg_alpha': 1.2758071038742542, 'reg_lambda': 0.6641140918929409}. Best is trial 2 with value: 0.3424657534246575.\n",
            "[I 2025-04-24 21:26:55,044] Trial 5 finished with value: 0.3282442748091603 and parameters: {'learning_rate': 0.021866979365182313, 'num_leaves': 170, 'max_depth': 10, 'min_child_weight': 3.9558497264872656, 'subsample': 0.7435790149996955, 'colsample_bytree': 0.6016192378879466, 'reg_alpha': 0.8240514847950116, 'reg_lambda': 1.9215631736560772}. Best is trial 2 with value: 0.3424657534246575.\n",
            "[I 2025-04-24 21:26:56,553] Trial 6 finished with value: 0.36283185840707965 and parameters: {'learning_rate': 0.07807320291927311, 'num_leaves': 66, 'max_depth': 9, 'min_child_weight': 1.9139471520615274, 'subsample': 0.5420872974279196, 'colsample_bytree': 0.6585154621599244, 'reg_alpha': 1.9240232725300006, 'reg_lambda': 1.5298916598426224}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:26:59,945] Trial 7 finished with value: 0.3582089552238806 and parameters: {'learning_rate': 0.12548710385731568, 'num_leaves': 231, 'max_depth': 13, 'min_child_weight': 0.17290887744562203, 'subsample': 0.605329031506292, 'colsample_bytree': 0.9570707251634839, 'reg_alpha': 1.2698666744914493, 'reg_lambda': 0.6692080157871296}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:02,482] Trial 8 finished with value: 0.3382352941176471 and parameters: {'learning_rate': 0.1864231444788433, 'num_leaves': 84, 'max_depth': 9, 'min_child_weight': 0.2470314880567396, 'subsample': 0.9350829897615376, 'colsample_bytree': 0.9181456245625942, 'reg_alpha': 1.834959518861468, 'reg_lambda': 1.0203758600344066}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:04,382] Trial 9 finished with value: 0.2830188679245283 and parameters: {'learning_rate': 0.2803809056991411, 'num_leaves': 179, 'max_depth': 12, 'min_child_weight': 0.0055896078879983015, 'subsample': 0.6505100459498216, 'colsample_bytree': 0.6753466596297412, 'reg_alpha': 0.28179860095702947, 'reg_lambda': 0.19107752524866806}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:05,815] Trial 10 finished with value: 0.3028571428571429 and parameters: {'learning_rate': 0.10145939695917655, 'num_leaves': 32, 'max_depth': 6, 'min_child_weight': 1.002521933040549, 'subsample': 0.5290656588704248, 'colsample_bytree': 0.7371636415040712, 'reg_alpha': 1.9773723353564034, 'reg_lambda': 1.6898208802363586}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:08,126] Trial 11 finished with value: 0.32061068702290074 and parameters: {'learning_rate': 0.10032836027315059, 'num_leaves': 247, 'max_depth': 7, 'min_child_weight': 0.36591992471801277, 'subsample': 0.6002980123467119, 'colsample_bytree': 0.7965045604803661, 'reg_alpha': 1.3651206630848274, 'reg_lambda': 1.3783318312484316}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:11,331] Trial 12 finished with value: 0.33766233766233766 and parameters: {'learning_rate': 0.11624749720882041, 'num_leaves': 244, 'max_depth': 11, 'min_child_weight': 0.6022463498505569, 'subsample': 0.5103961250452441, 'colsample_bytree': 0.6537616378664204, 'reg_alpha': 1.1739252197155399, 'reg_lambda': 1.2983120290283385}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:15,617] Trial 13 finished with value: 0.28205128205128205 and parameters: {'learning_rate': 0.06522901640032056, 'num_leaves': 35, 'max_depth': 8, 'min_child_weight': 0.1122101608532969, 'subsample': 0.6028257548927551, 'colsample_bytree': 0.8495183705292644, 'reg_alpha': 1.5950626745820218, 'reg_lambda': 1.4618621791997235}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:18,640] Trial 14 finished with value: 0.2647058823529412 and parameters: {'learning_rate': 0.13473492329811532, 'num_leaves': 221, 'max_depth': 15, 'min_child_weight': 7.583611732072746, 'subsample': 0.8204192228594558, 'colsample_bytree': 0.5076303570728522, 'reg_alpha': 0.4347829349566431, 'reg_lambda': 1.0241054812662644}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:22,481] Trial 15 finished with value: 0.32432432432432434 and parameters: {'learning_rate': 0.06800663280870567, 'num_leaves': 212, 'max_depth': 12, 'min_child_weight': 0.019739341953232577, 'subsample': 0.6505751644865844, 'colsample_bytree': 0.6909944394061123, 'reg_alpha': 1.0450410320011758, 'reg_lambda': 0.7767457503648425}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:23,475] Trial 16 finished with value: 0.3018867924528302 and parameters: {'learning_rate': 0.016378630559369695, 'num_leaves': 142, 'max_depth': 13, 'min_child_weight': 1.4255530978420399, 'subsample': 0.5864216870699728, 'colsample_bytree': 0.6172318801795506, 'reg_alpha': 1.5215187677765778, 'reg_lambda': 1.9948413878406996}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:25,369] Trial 17 finished with value: 0.34210526315789475 and parameters: {'learning_rate': 0.13480078150514693, 'num_leaves': 61, 'max_depth': 10, 'min_child_weight': 0.16184118889262095, 'subsample': 0.5078269562129426, 'colsample_bytree': 0.7416354546968382, 'reg_alpha': 1.7429322313550806, 'reg_lambda': 1.2290860756153261}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:27,366] Trial 18 finished with value: 0.31788079470198677 and parameters: {'learning_rate': 0.22473369380606847, 'num_leaves': 129, 'max_depth': 8, 'min_child_weight': 6.328816493822111, 'subsample': 0.794623840217284, 'colsample_bytree': 0.8678317664513691, 'reg_alpha': 1.9990571345757338, 'reg_lambda': 1.67097532477085}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:29,607] Trial 19 finished with value: 0.3516483516483517 and parameters: {'learning_rate': 0.054851768544791873, 'num_leaves': 213, 'max_depth': 11, 'min_child_weight': 0.021649120858194114, 'subsample': 0.7040574411296231, 'colsample_bytree': 0.7880748173134624, 'reg_alpha': 0.035949943795925865, 'reg_lambda': 0.38443408451908645}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:31,349] Trial 20 finished with value: 0.3125 and parameters: {'learning_rate': 0.1498720089559126, 'num_leaves': 72, 'max_depth': 15, 'min_child_weight': 2.4241886319023345, 'subsample': 0.6373670260851478, 'colsample_bytree': 0.7188749008216041, 'reg_alpha': 1.384099453612988, 'reg_lambda': 0.8202903732887361}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:33,646] Trial 21 finished with value: 0.29411764705882354 and parameters: {'learning_rate': 0.08001461249245927, 'num_leaves': 209, 'max_depth': 11, 'min_child_weight': 0.021530879896516426, 'subsample': 0.7034274633547654, 'colsample_bytree': 0.792017980420734, 'reg_alpha': 0.50883524290447, 'reg_lambda': 0.39263804867720414}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:36,204] Trial 22 finished with value: 0.334841628959276 and parameters: {'learning_rate': 0.04746148514424849, 'num_leaves': 225, 'max_depth': 10, 'min_child_weight': 0.01745716726203071, 'subsample': 0.5618181250395634, 'colsample_bytree': 0.9188186091539126, 'reg_alpha': 0.22913092622834985, 'reg_lambda': 0.05621484735764093}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:39,067] Trial 23 finished with value: 0.2923076923076923 and parameters: {'learning_rate': 0.08929204227693721, 'num_leaves': 187, 'max_depth': 13, 'min_child_weight': 0.006915089560078597, 'subsample': 0.6258302601706799, 'colsample_bytree': 0.6365005206253822, 'reg_alpha': 0.140611111596475, 'reg_lambda': 0.5892449385264389}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:40,988] Trial 24 finished with value: 0.3522727272727273 and parameters: {'learning_rate': 0.0447276124218125, 'num_leaves': 201, 'max_depth': 11, 'min_child_weight': 0.05052429242590763, 'subsample': 0.7016869755192037, 'colsample_bytree': 0.5712302790710919, 'reg_alpha': 0.0020164381679927956, 'reg_lambda': 0.3113793888535583}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:42,597] Trial 25 finished with value: 0.30303030303030304 and parameters: {'learning_rate': 0.12087225500545967, 'num_leaves': 255, 'max_depth': 13, 'min_child_weight': 0.45802764201915813, 'subsample': 0.7744389178513718, 'colsample_bytree': 0.5669296393651758, 'reg_alpha': 1.0455758009468952, 'reg_lambda': 1.1592105820347143}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:43,690] Trial 26 finished with value: 0.3044982698961938 and parameters: {'learning_rate': 0.02976907085945428, 'num_leaves': 192, 'max_depth': 9, 'min_child_weight': 0.06875796299731322, 'subsample': 0.5508559315900743, 'colsample_bytree': 0.5816677218301924, 'reg_alpha': 0.8149765346847488, 'reg_lambda': 1.5788968273432018}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:44,952] Trial 27 finished with value: 0.3275862068965517 and parameters: {'learning_rate': 0.08154145089324481, 'num_leaves': 151, 'max_depth': 8, 'min_child_weight': 0.16885625633083207, 'subsample': 0.8309183452081512, 'colsample_bytree': 0.5084228622243298, 'reg_alpha': 0.5776181794818508, 'reg_lambda': 0.2641389284181088}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:46,390] Trial 28 finished with value: 0.30042918454935624 and parameters: {'learning_rate': 0.03819673801042995, 'num_leaves': 232, 'max_depth': 11, 'min_child_weight': 0.9457650074115271, 'subsample': 0.6797591488062362, 'colsample_bytree': 0.5388529008058817, 'reg_alpha': 1.2200373841913748, 'reg_lambda': 0.7299100460467925}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:48,670] Trial 29 finished with value: 0.26666666666666666 and parameters: {'learning_rate': 0.11373088128553303, 'num_leaves': 196, 'max_depth': 14, 'min_child_weight': 0.0425383097753932, 'subsample': 0.6722756419810576, 'colsample_bytree': 0.700434272519942, 'reg_alpha': 0.36732646195380436, 'reg_lambda': 0.5512421653221081}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:50,001] Trial 30 finished with value: 0.3057324840764331 and parameters: {'learning_rate': 0.0675863647894027, 'num_leaves': 154, 'max_depth': 7, 'min_child_weight': 0.0976252171123673, 'subsample': 0.586179623416041, 'colsample_bytree': 0.6582055003889185, 'reg_alpha': 0.7224260208302373, 'reg_lambda': 0.30876207001228884}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:53,141] Trial 31 finished with value: 0.32160804020100503 and parameters: {'learning_rate': 0.05373771213655908, 'num_leaves': 206, 'max_depth': 11, 'min_child_weight': 0.013413279471284663, 'subsample': 0.7196205883116259, 'colsample_bytree': 0.876204710679945, 'reg_alpha': 0.14026006091341092, 'reg_lambda': 0.5095334339517037}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:56,703] Trial 32 finished with value: 0.3 and parameters: {'learning_rate': 0.09088909673088313, 'num_leaves': 234, 'max_depth': 12, 'min_child_weight': 0.03632744369381073, 'subsample': 0.6847650355042558, 'colsample_bytree': 0.995037724844706, 'reg_alpha': 0.019182657833065456, 'reg_lambda': 0.037514532690222424}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:27:59,172] Trial 33 finished with value: 0.24074074074074073 and parameters: {'learning_rate': 0.012494043774775317, 'num_leaves': 118, 'max_depth': 14, 'min_child_weight': 0.0029877865685670646, 'subsample': 0.711103279244617, 'colsample_bytree': 0.7723317298904285, 'reg_alpha': 0.005475475378340363, 'reg_lambda': 0.420354400715299}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:28:01,133] Trial 34 finished with value: 0.32599118942731276 and parameters: {'learning_rate': 0.05484858586403815, 'num_leaves': 199, 'max_depth': 10, 'min_child_weight': 0.03697158873552107, 'subsample': 0.7628698214098829, 'colsample_bytree': 0.8427117503815883, 'reg_alpha': 0.6508000334748416, 'reg_lambda': 0.8747809260105942}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:28:03,993] Trial 35 finished with value: 0.2857142857142857 and parameters: {'learning_rate': 0.16600179839994222, 'num_leaves': 51, 'max_depth': 13, 'min_child_weight': 0.010816349362042597, 'subsample': 0.5414506177738898, 'colsample_bytree': 0.9543313289448031, 'reg_alpha': 1.7075216266457485, 'reg_lambda': 0.6433954247169648}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:28:05,641] Trial 36 finished with value: 0.33088235294117646 and parameters: {'learning_rate': 0.0389323488720382, 'num_leaves': 104, 'max_depth': 9, 'min_child_weight': 0.06517978943426213, 'subsample': 0.6270326105874561, 'colsample_bytree': 0.6311978984179186, 'reg_alpha': 0.9200199770188319, 'reg_lambda': 0.43006203724887937}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:28:07,676] Trial 37 finished with value: 0.2905982905982906 and parameters: {'learning_rate': 0.1474363159443637, 'num_leaves': 220, 'max_depth': 11, 'min_child_weight': 0.0026408416875708172, 'subsample': 0.8819353905842522, 'colsample_bytree': 0.5933344309246389, 'reg_alpha': 0.10734893156115237, 'reg_lambda': 0.2778368033121781}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:28:09,491] Trial 38 finished with value: 0.2702702702702703 and parameters: {'learning_rate': 0.1831640844118436, 'num_leaves': 166, 'max_depth': 10, 'min_child_weight': 0.2621401105616551, 'subsample': 0.7291763210093515, 'colsample_bytree': 0.5430759875053266, 'reg_alpha': 0.2368551347492254, 'reg_lambda': 0.17117948963706806}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:28:10,540] Trial 39 finished with value: 0.3137254901960784 and parameters: {'learning_rate': 0.2076022666497938, 'num_leaves': 235, 'max_depth': 5, 'min_child_weight': 3.293313562357083, 'subsample': 0.5700087737298116, 'colsample_bytree': 0.9572230013012808, 'reg_alpha': 0.32681095952928807, 'reg_lambda': 1.0949096427933616}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:28:12,085] Trial 40 finished with value: 0.3157894736842105 and parameters: {'learning_rate': 0.10611648414582603, 'num_leaves': 176, 'max_depth': 12, 'min_child_weight': 0.008598720680319792, 'subsample': 0.6151248525381352, 'colsample_bytree': 0.6100889309769186, 'reg_alpha': 1.89877311649485, 'reg_lambda': 0.9294851259226974}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:28:12,756] Trial 41 finished with value: 0.3028391167192429 and parameters: {'learning_rate': 0.16959178929977803, 'num_leaves': 79, 'max_depth': 5, 'min_child_weight': 0.001434025598590894, 'subsample': 0.9862954632892239, 'colsample_bytree': 0.5599750078901986, 'reg_alpha': 1.3909130413559674, 'reg_lambda': 0.1375690099636999}. Best is trial 6 with value: 0.36283185840707965.\n",
            "[I 2025-04-24 21:28:13,901] Trial 42 finished with value: 0.38372093023255816 and parameters: {'learning_rate': 0.24019809432229017, 'num_leaves': 89, 'max_depth': 6, 'min_child_weight': 0.0041817950637111564, 'subsample': 0.8706663190474906, 'colsample_bytree': 0.8266276411298646, 'reg_alpha': 1.1346351404512183, 'reg_lambda': 0.3378640853685271}. Best is trial 42 with value: 0.38372093023255816.\n",
            "[I 2025-04-24 21:28:15,616] Trial 43 finished with value: 0.3283582089552239 and parameters: {'learning_rate': 0.2941523737859307, 'num_leaves': 96, 'max_depth': 7, 'min_child_weight': 0.003348361598847058, 'subsample': 0.8704443645298324, 'colsample_bytree': 0.8240246809504087, 'reg_alpha': 1.1214108641202531, 'reg_lambda': 0.35231350597854816}. Best is trial 42 with value: 0.38372093023255816.\n",
            "[I 2025-04-24 21:28:17,224] Trial 44 finished with value: 0.4 and parameters: {'learning_rate': 0.25251661386671315, 'num_leaves': 50, 'max_depth': 6, 'min_child_weight': 0.028552180392881724, 'subsample': 0.9499291808280579, 'colsample_bytree': 0.7636671182456942, 'reg_alpha': 1.2996484821796774, 'reg_lambda': 0.5055938828879819}. Best is trial 44 with value: 0.4.\n",
            "[I 2025-04-24 21:28:18,356] Trial 45 finished with value: 0.3270440251572327 and parameters: {'learning_rate': 0.2495783253401886, 'num_leaves': 61, 'max_depth': 6, 'min_child_weight': 0.7191981457555111, 'subsample': 0.9430474321264154, 'colsample_bytree': 0.7609660312912789, 'reg_alpha': 1.2629091182114172, 'reg_lambda': 0.47941571804879746}. Best is trial 44 with value: 0.4.\n",
            "[I 2025-04-24 21:28:20,033] Trial 46 finished with value: 0.3125 and parameters: {'learning_rate': 0.2578011901309014, 'num_leaves': 43, 'max_depth': 7, 'min_child_weight': 0.0010006325214812802, 'subsample': 0.939950661047487, 'colsample_bytree': 0.895366385896151, 'reg_alpha': 0.9491867593259693, 'reg_lambda': 0.6637093830299192}. Best is trial 44 with value: 0.4.\n",
            "[I 2025-04-24 21:28:21,236] Trial 47 finished with value: 0.3687150837988827 and parameters: {'learning_rate': 0.23193996150077625, 'num_leaves': 60, 'max_depth': 6, 'min_child_weight': 0.028840628514719326, 'subsample': 0.9740584715242027, 'colsample_bytree': 0.8182913988239536, 'reg_alpha': 1.496732173060367, 'reg_lambda': 1.8281466374654705}. Best is trial 44 with value: 0.4.\n",
            "[I 2025-04-24 21:28:22,335] Trial 48 finished with value: 0.3583815028901734 and parameters: {'learning_rate': 0.23148924325909992, 'num_leaves': 61, 'max_depth': 6, 'min_child_weight': 0.005154728462167856, 'subsample': 0.9119549757097347, 'colsample_bytree': 0.8194559543982237, 'reg_alpha': 1.4978556187093688, 'reg_lambda': 1.8647901379547431}. Best is trial 44 with value: 0.4.\n",
            "[I 2025-04-24 21:28:23,466] Trial 49 finished with value: 0.3617021276595745 and parameters: {'learning_rate': 0.23142760164000648, 'num_leaves': 66, 'max_depth': 6, 'min_child_weight': 0.00408524055925108, 'subsample': 0.9648456641477013, 'colsample_bytree': 0.8190335184856432, 'reg_alpha': 1.6237915900004867, 'reg_lambda': 1.8271129819232097}. Best is trial 44 with value: 0.4.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial:\n",
            "FrozenTrial(number=44, state=1, values=[0.4], datetime_start=datetime.datetime(2025, 4, 24, 21, 28, 15, 620821), datetime_complete=datetime.datetime(2025, 4, 24, 21, 28, 17, 223838), params={'learning_rate': 0.25251661386671315, 'num_leaves': 50, 'max_depth': 6, 'min_child_weight': 0.028552180392881724, 'subsample': 0.9499291808280579, 'colsample_bytree': 0.7636671182456942, 'reg_alpha': 1.2996484821796774, 'reg_lambda': 0.5055938828879819}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.3, log=False, low=0.01, step=None), 'num_leaves': IntDistribution(high=256, log=False, low=31, step=1), 'max_depth': IntDistribution(high=15, log=False, low=5, step=1), 'min_child_weight': FloatDistribution(high=10.0, log=True, low=0.001, step=None), 'subsample': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'reg_alpha': FloatDistribution(high=2.0, log=False, low=0.0, step=None), 'reg_lambda': FloatDistribution(high=2.0, log=False, low=0.0, step=None)}, trial_id=44, value=None)\n",
            "\n",
            "F1 Score: 0.4\n",
            "\n",
            "Confusion Matrix:\n",
            " [[677  45]\n",
            " [ 48  31]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.94       722\n",
            "           1       0.41      0.39      0.40        79\n",
            "\n",
            "    accuracy                           0.88       801\n",
            "   macro avg       0.67      0.67      0.67       801\n",
            "weighted avg       0.88      0.88      0.88       801\n",
            "\n",
            "   Actual  Predicted\n",
            "0       0          0\n",
            "1       0          0\n",
            "2       0          0\n",
            "3       0          0\n",
            "4       0          0\n"
          ]
        }
      ]
    }
  ]
}