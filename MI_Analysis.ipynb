{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clv07/stroke-of-luck/blob/Data-import/MI_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsQ4J7k9DfR6"
      },
      "outputs": [],
      "source": [
        "from os import read\n",
        "import csv\n",
        "import pandas\n",
        "import numpy as np\n",
        "\n",
        "# Create Code Dictionary:\n",
        "MI_stmnts_12SL = [740,810,820, ## anterior infarct\n",
        "                  700,810, ## septal infarct\n",
        "                  760,820, ## lateral infarct\n",
        "                  780,801,806, ## inferior infarct\n",
        "                  801,802,803, ## posterior infarct\n",
        "                  826,827,963,964,965,966,967,968, ## infarct - ST elevation\n",
        "                  4,821,822,823,826,827,828,829,920,930,940,950,960,961,962,1361, ## acute MI or injury\n",
        "                  ]\n",
        "MI_stmnts_12SL = set(MI_stmnts_12SL)\n",
        "#Read in Results.csv\n",
        "\n",
        "#Read in 12SL\n",
        "\n",
        "\n",
        "\n",
        "# Basic Error Rate for MI\n",
        "# - Look for physician codes that includes:\n",
        "# -\n",
        "# Acute MI (STEMI)\n",
        "# Bayes Theorem\n",
        "# False Positives"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "###############################################################################\n",
        "# STEP 1: READ AND PROCESS EACH 12SL CSV\n",
        "###############################################################################\n",
        "def read_and_process_12sl(csv_path, dataset_name=None):\n",
        "    \"\"\"\n",
        "    Reads a 12SL CSV file and returns a DataFrame with:\n",
        "      - 'TestID' (the patient identifier)\n",
        "      - 'Statement_codes' (a comma-separated string of codes)\n",
        "      - A 'Source' column to indicate which dataset it came from\n",
        "\n",
        "    \"\"\"\n",
        "    df_raw = pd.read_csv(csv_path)\n",
        "\n",
        "    # Rename the first column to \"TestID\"\n",
        "    first_col = df_raw.columns[0]\n",
        "    df_raw.rename(columns={first_col: \"TestID\"}, inplace=True)\n",
        "\n",
        "    # for results.csv -> only 2 columns\n",
        "    if len(df_raw.columns) == 2:\n",
        "        # convert | to commas (,)\n",
        "        df_raw[\"Statement_codes\"] = (\n",
        "            df_raw[\"Statements\"]\n",
        "            .astype(str)\n",
        "            .str.strip(\"|\")\n",
        "            .str.replace(\"|\", \",\")\n",
        "        )\n",
        "    else:\n",
        "        # for the 12SL output (mulitple columns for codes)\n",
        "        code_cols = df_raw.columns[1:]\n",
        "        def combine_codes(row):\n",
        "            valid = row.dropna().astype(str)\n",
        "            return \",\".join(valid)\n",
        "        df_raw[\"Statement_codes\"] = df_raw[code_cols].apply(combine_codes, axis=1)\n",
        "\n",
        "    # Keep only TestID and Statement_codes (we no longer need the original \"Statements\" or other columns)\n",
        "    df_processed = df_raw[[\"TestID\", \"Statement_codes\"]].copy()\n",
        "\n",
        "    # Standardize patient IDs if needed.\n",
        "    # For example, in your Shaoxing_12SL sample, TestID is a number (e.g., 1) but in results.csv\n",
        "    # the patient IDs are like \"JS00001\". Here we convert if dataset_name==\"Shaoxing\".\n",
        "    if dataset_name == \"Shaoxing\":\n",
        "        df_processed[\"TestID\"] = df_processed[\"TestID\"].apply(lambda x: f\"JS{int(x):05d}\")\n",
        "    # If you have similar rules for other datasets, add them here.\n",
        "\n",
        "    # Optionally add a column to record the source dataset.\n",
        "    if dataset_name:\n",
        "        df_processed[\"Source\"] = dataset_name\n",
        "\n",
        "    return df_processed\n",
        "\n",
        "# Example file paths (update these paths as needed)\n",
        "ptbxl_csv    = r\"./PTBXL_12SL.csv\"      # adjust if format differs\n",
        "shaoxing_csv = r\"./Shaoxing_12SL.csv\"   # sample provided above\n",
        "cpsc_csv     = r\"./CPSC2018_12SL.csv\"     # adjust if format differs\n",
        "\n",
        "# Process each CSV.\n",
        "# (If PTBXL or CPSC files are in a wide format and already use the desired ID format,\n",
        "#  you might not need to convert their IDs.)\n",
        "df_ptbxl    = read_and_process_12sl(ptbxl_csv, dataset_name=\"PTBXL\")\n",
        "df_shaoxing = read_and_process_12sl(shaoxing_csv, dataset_name=\"Shaoxing\")\n",
        "df_cpsc     = read_and_process_12sl(cpsc_csv, dataset_name=\"CPSC2018\")\n",
        "\n",
        "# Concatenate all 12SL data.\n",
        "df_12sl_combined = pd.concat([df_ptbxl, df_shaoxing, df_cpsc], ignore_index=True)\n",
        "\n",
        "###############################################################################\n",
        "# STEP 2: READ AND PREPARE THE results.csv (PHYSICIAN CODES)\n",
        "###############################################################################\n",
        "results_csv = r\"./results.csv\"\n",
        "df_results = pd.read_csv(results_csv)\n",
        "\n",
        "# The results.csv sample has headers: patient_num and codes.\n",
        "# Rename these to \"TestID\" and \"Statements_Phys\" so that we can merge.\n",
        "df_results.rename(columns={\"patient_num\": \"TestID\", \"codes\": \"Statements_Phys\"}, inplace=True)\n",
        "\n",
        "# It may be necessary to strip any extra spaces from the codes:\n",
        "df_results[\"Statements_Phys\"] = df_results[\"Statements_Phys\"].astype(str).str.strip()\n",
        "\n",
        "###############################################################################\n",
        "# STEP 3: MERGE THE 12SL DATA WITH THE PHYSICIAN DATA\n",
        "###############################################################################\n",
        "# Merge on the patient ID. Use inner join if you want only matching IDs.\n",
        "df_merged = pd.merge(df_12sl_combined, df_results, on=\"TestID\", how=\"inner\")\n",
        "\n",
        "###############################################################################\n",
        "# STEP 4: DEFINE MI CODE SETS AND CREATE BINARY INDICATORS\n",
        "###############################################################################\n",
        "# Example MI code sets (update these with the actual codes you consider for MI)\n",
        "MI_codes_12SL = {\n",
        "    700, 740, 760, 780, 801, 810, 820, 826, 827, 828, 829,\n",
        "    920, 930, 940, 950, 960, 961, 962, 963, 964, 965, 966, 967, 968,\n",
        "    # ... add others as needed\n",
        "}\n",
        "\n",
        "MI_codes_Phys = {\n",
        "    57054005, 413444003, 426434006, 54329005, 425419005,\n",
        "    425623009, 164865005, 164861001,\n",
        "    # ... add others as needed\n",
        "}\n",
        "# Pairs matching codes from different systems to common condition, formatted\n",
        "# \"Conditon\" : [num_one, num_two ...] , use to identify shared diagnoses\n",
        "# between physicians and 12SL\n",
        "MI_code_mapping = {\n",
        "    \"anterior infarct\": [740, 810, 820, 54329005],\n",
        "    \"septal infarct\": [700, 810],\n",
        "    \"lateral infarct\": [760, 820, 425623009],\n",
        "    \"inferior infarct\": [780, 801, 806, 425419005],\n",
        "    \"posterior infarct\": [801, 802, 803],\n",
        "    \"infarct - ST elevation\": [826, 827, 963, 964, 965, 966, 967, 968],\n",
        "    \"acute MI or injury\": [4, 821, 822, 823, 826, 827, 828, 829, 920, 930, 940, 950, 960, 961, 962, 1361, 57054005, 413444003, 426434006, 164865005, 164861001]\n",
        "}\n",
        "\n",
        "def flag_mi(codes_str, mi_set):\n",
        "    \"\"\"\n",
        "    Given a string of codes separated by commas (possibly with spaces),\n",
        "    returns 1 if any code (converted to int) is in the mi_set, else 0.\n",
        "    \"\"\"\n",
        "    if pd.isna(codes_str) or codes_str.strip() == \"\":\n",
        "        return 0\n",
        "    codes = [c.strip() for c in codes_str.split(\",\") if c.strip()]\n",
        "    for code in codes:\n",
        "        try:\n",
        "            if int(code) in mi_set:\n",
        "                return 1\n",
        "        except ValueError:\n",
        "            continue\n",
        "    return 0\n",
        "\n",
        "def GivenXInspection(df, codes_str, mi_column, mi_code_mapping):\n",
        "    \"\"\"\n",
        "    Given a Merged DF with 1) Patient Labels, 2) 12SL Codes, 3) Physician Codes,\n",
        "    4) MI_12SL, 5) MI_Phys, determine the probability of 12SL correctly identifying\n",
        "    a symptom given a set of codes (i.e., Probability of 12SL detecting MI given ST Elevation).\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The merged dataframe containing MI flags.\n",
        "        codes_str (str): A condition category representing the \"given\" signal (e.g., \"anterior infarct\").\n",
        "        mi_column (str): The column name representing the 12SL calculated Condition flag (e.g., \"MI_12SL\").\n",
        "        mi_code_mapping (dict): A dictionary mapping condition categories to a list of associated codes.\n",
        "\n",
        "    Returns:\n",
        "        float: Probability of correct identification.\n",
        "    \"\"\"\n",
        "    # Get the relevant codes for the given condition\n",
        "    condition_codes = set(mi_code_mapping.get(codes_str, []))\n",
        "\n",
        "    # Convert Statements_Phys to sets for efficient lookup\n",
        "    df[\"Statements_Phys_Set\"] = df[\"Statements_Phys\"].apply(lambda x: set(map(int, x.split(','))) if pd.notna(x) else set())\n",
        "\n",
        "    # Identify cases where at least one given condition code is present in the physician's statements\n",
        "    signal_present = df[df[\"Statements_Phys_Set\"].apply(lambda codes: not condition_codes.isdisjoint(codes))]\n",
        "\n",
        "    # Further filter cases where the physician also flagged MI\n",
        "    mi_positive_patients = signal_present.loc[signal_present[\"MI_Phys\"] == 1, \"TestID\"]\n",
        "\n",
        "    if mi_positive_patients.empty:\n",
        "        return 0  # Avoid division by zero if no cases exist\n",
        "\n",
        "    # Filter 12SL-flagged cases only for identified patients\n",
        "    correct_identifications = df.loc[df[\"TestID\"].isin(mi_positive_patients), mi_column].sum()\n",
        "\n",
        "    # Calculate probability\n",
        "    probability = correct_identifications / len(mi_positive_patients)\n",
        "\n",
        "    return probability\n",
        "\n",
        "def LabelMapping(df_merged, mi_code_mapping):\n",
        "    \"\"\"\n",
        "    Given a Merged DF with 1) Patient Labels, 2) 12SL Codes, 3) Physician Codes,\n",
        "    4) MI_12SL, 5) MI_Phys, break down the identified signs by 12SL & Physicians\n",
        "    to categorize label percentages in missed and false flag cases.\n",
        "\n",
        "    Args:\n",
        "        df_merged (pd.DataFrame): The merged dataframe containing MI-related flags.\n",
        "        mi_code_mapping (dict): A dictionary mapping condition categories to lists of associated codes.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Two DataFrames -\n",
        "            - df_code_percentages: Breakdown of missed/false flag percentages per code.\n",
        "            - df_signal_percentages: Breakdown of missed/false flag percentages per condition category.\n",
        "    \"\"\"\n",
        "\n",
        "    # Gather cases flagged by physicians but missed by 12SL\n",
        "    df_missed_by_12sl = df_merged[(df_merged[\"MI_Phys\"] == 1) & (df_merged[\"MI_12SL\"] == 0)]\n",
        "\n",
        "    # Gather cases flagged by 12SL but not confirmed by physicians\n",
        "    df_false_id = df_merged[(df_merged[\"MI_12SL\"] == 1) & (df_merged[\"MI_Phys\"] == 0)]\n",
        "\n",
        "    # Function to count occurrences of each code\n",
        "    def count_codes(df):\n",
        "        code_counts = {}\n",
        "        for codes in df[\"Statements_Phys\"].dropna():\n",
        "            for code in map(int, codes.split(',')):  # Convert to int to ensure consistency\n",
        "                code_counts[code] = code_counts.get(code, 0) + 1\n",
        "        return code_counts\n",
        "\n",
        "    # Count occurrences in missed and false flag cases\n",
        "    missed_code_counts = count_codes(df_missed_by_12sl)\n",
        "    false_code_counts = count_codes(df_false_id)\n",
        "\n",
        "    # Convert counts to DataFrames\n",
        "    df_code_percentages = pd.DataFrame([\n",
        "        {\"Code\": code,\n",
        "         \"Missed_Percentage\": missed_code_counts.get(code, 0) / len(df_missed_by_12sl) * 100 if len(df_missed_by_12sl) > 0 else 0,\n",
        "         \"False_Flag_Percentage\": false_code_counts.get(code, 0) / len(df_false_id) * 100 if len(df_false_id) > 0 else 0}\n",
        "        for code in set(missed_code_counts) | set(false_code_counts)  # Include all unique codes\n",
        "    ])\n",
        "\n",
        "    # Aggregate by signal type (condition category)\n",
        "    signal_counts = {}\n",
        "    for condition, codes in mi_code_mapping.items():\n",
        "        signal_counts[condition] = {\n",
        "            \"Missed_Percentage\": sum(missed_code_counts.get(code, 0) for code in codes) / len(df_missed_by_12sl) * 100 if len(df_missed_by_12sl) > 0 else 0,\n",
        "            \"False_Flag_Percentage\": sum(false_code_counts.get(code, 0) for code in codes) / len(df_false_id) * 100 if len(df_false_id) > 0 else 0\n",
        "        }\n",
        "\n",
        "    df_signal_percentages = pd.DataFrame.from_dict(signal_counts, orient=\"index\").reset_index().rename(columns={\"index\": \"Condition\"})\n",
        "\n",
        "    return df_code_percentages, df_signal_percentages\n",
        "# Create MI flags for 12SL and Physician.\n",
        "df_merged[\"MI_12SL\"] = df_merged[\"Statement_codes\"].apply(lambda x: flag_mi(x, MI_codes_12SL))\n",
        "df_merged[\"MI_Phys\"]  = df_merged[\"Statements_Phys\"].apply(lambda x: flag_mi(x, MI_codes_Phys))\n",
        "\n",
        "###############################################################################\n",
        "# STEP 5: INSPECTION / ANALYSIS\n",
        "###############################################################################\n",
        "print(\"Merged Data Sample:\")\n",
        "print(df_merged.head(10))\n",
        "print(df_merged.columns)\n",
        "print(f\"Total merged records: {len(df_merged)}\")\n",
        "print(f\"Total MI flagged by 12SL: {df_merged['MI_12SL'].sum()}\")\n",
        "print(f\"Total MI flagged by Physician: {df_merged['MI_Phys'].sum()}\")\n",
        "\n",
        "# For example, cases flagged by Physician but not by 12SL (False Negative):\n",
        "df_missed_by_12sl = df_merged[(df_merged[\"MI_Phys\"] == 1) & (df_merged[\"MI_12SL\"] == 0)]\n",
        "print(f\"Records where Physician flagged MI but 12SL did not: {len(df_missed_by_12sl)}\")\n",
        "\n",
        "# Case 2) Cases Flagged by 12SL but not by Physician (False Positive)\n",
        "df_false_id = df_merged[(df_merged[\"MI_12SL\"] == 1) & (df_merged[\"MI_Phys\"] == 0)]\n",
        "print(f\"Records where 12SL flagged MI but Physician did not: {len(df_false_id)}\")\n",
        "\n",
        "# Case 3)\n",
        "# a) Given STEMI, What is the chance that 12SL calculated it correctly\n",
        "prob_given_STElevation = GivenXInspection(df_merged,\"infarct - ST elevation\",\"MI_12SL\", MI_code_mapping)\n",
        "print(f\"Probability of 12SL identifying MI given ST Elevation: {prob_given_STElevation}\")\n",
        "# b) Given MI, What is the chance that 12SL calculated it correctly\n",
        "prob_given_lateral = GivenXInspection(df_merged,\"acute MI or injury\",\"MI_12SL\", MI_code_mapping)\n",
        "print(f\"Probability of 12SL identifying MI given MI or Injury: {prob_given_lateral}\")\n",
        "# Conditional Breakdown of Missed regions\n",
        "breakdown = LabelMapping(df_merged, MI_code_mapping)\n",
        "print(breakdown[0].head(10))\n",
        "print(breakdown[1].head(10))\n",
        "# Optionally, export the final merged data:\n",
        "df_merged.to_csv(\"merged_output.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "-YcrPCe2Qz3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "640eebf8-58d3-403e-82f7-45cd059238bc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged Data Sample:\n",
            "    TestID                 Statement_codes    Source  \\\n",
            "0  JS00001        161,171,440,700,831,1699  Shaoxing   \n",
            "1  JS00002                    21,1140,1699  Shaoxing   \n",
            "2  JS00004  23,542,1665,533,1666,1141,1699  Shaoxing   \n",
            "3  JS00005                         21,1687  Shaoxing   \n",
            "4  JS00006                   161,1140,1699  Shaoxing   \n",
            "5  JS00007                         22,1684  Shaoxing   \n",
            "6  JS00008                         21,1687  Shaoxing   \n",
            "7  JS00009                         21,1687  Shaoxing   \n",
            "8  JS00010       21,542,1665,531,1666,1693  Shaoxing   \n",
            "9  JS00011                         23,1687  Shaoxing   \n",
            "\n",
            "                   Statements_Phys  MI_12SL  MI_Phys  \n",
            "0   164889003, 59118001, 164934002        1        0  \n",
            "1             426177001, 164934002        0        0  \n",
            "2                        426177001        0        0  \n",
            "3  164890007, 429622005, 428750005        0        0  \n",
            "4                        426177001        0        0  \n",
            "5             164889003, 164934002        0        0  \n",
            "6                        426783006        0        0  \n",
            "7                        426177001        0        0  \n",
            "8                        426177001        0        0  \n",
            "9              426177001, 55827005        0        0  \n",
            "Index(['TestID', 'Statement_codes', 'Source', 'Statements_Phys', 'MI_12SL',\n",
            "       'MI_Phys'],\n",
            "      dtype='object')\n",
            "Total merged records: 44748\n",
            "Total MI flagged by 12SL: 3547\n",
            "Total MI flagged by Physician: 201\n",
            "Records where Physician flagged MI but 12SL did not: 170\n",
            "Records where 12SL flagged MI but Physician did not: 3516\n",
            "Probability of 12SL identifying MI given ST Elevation: 0\n",
            "Probability of 12SL identifying MI given MI or Injury: 0.16774193548387098\n",
            "        Code  Missed_Percentage  False_Flag_Percentage\n",
            "0   54016002           0.000000               0.028441\n",
            "1   89792004           0.000000               0.341297\n",
            "2  425856008           3.529412               0.113766\n",
            "3   11157007           0.000000               0.028441\n",
            "4   81898007           0.000000               0.227531\n",
            "5   49578007           0.000000               0.085324\n",
            "6  251199005           0.000000               0.511945\n",
            "7  106068003           1.764706               0.853242\n",
            "8    5609005           0.588235               0.142207\n",
            "9  233897008           0.000000               0.227531\n",
            "                Condition  Missed_Percentage  False_Flag_Percentage\n",
            "0        anterior infarct          29.411765                    0.0\n",
            "1          septal infarct           0.000000                    0.0\n",
            "2         lateral infarct           0.000000                    0.0\n",
            "3        inferior infarct           0.000000                    0.0\n",
            "4       posterior infarct           0.000000                    0.0\n",
            "5  infarct - ST elevation           0.000000                    0.0\n",
            "6      acute MI or injury          82.352941                    0.0\n"
          ]
        }
      ]
    }
  ]
}