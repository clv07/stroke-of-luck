{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('positive.csv', na_values=['NULL'])\n",
    "\n",
    "df2 = pd.read_csv('negative.csv', na_values=['NULL'])\n",
    "\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "df['AcquisitionDateTime_DT'] = pd.to_datetime(df['AcquisitionDateTime_DT'])\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print(df.info())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret import show\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y = df[\"MI_Phys\"]\n",
    "X = df.drop(columns=[\"PatientID\", \"12SL_Codes\", \"Phys_Codes\", \"TestID\", \"Source\", \n",
    "                     \"Gender\", \"PatientAge\", \"AcquisitionDateTime_DT\", \"MI_Phys\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Save the original algorithm's prediction for test set before dropping it\n",
    "y_12SL = X_test[\"MI_12SL\"]\n",
    "\n",
    "# Split data based on MI_12SL classification\n",
    "X_train_pos = X_train[X_train[\"MI_12SL\"] == 1].drop(columns=[\"MI_12SL\"])\n",
    "X_train_neg = X_train[X_train[\"MI_12SL\"] == 0].drop(columns=[\"MI_12SL\"])\n",
    "X_test_pos = X_test[X_test[\"MI_12SL\"] == 1].drop(columns=[\"MI_12SL\"])\n",
    "X_test_neg = X_test[X_test[\"MI_12SL\"] == 0].drop(columns=[\"MI_12SL\"])\n",
    "\n",
    "# Ensure y labels match the correct samples\n",
    "y_train_pos = y_train.loc[X_train_pos.index]  # True positives or false positives\n",
    "y_train_neg = y_train.loc[X_train_neg.index]  # True negatives or false negatives\n",
    "y_test_pos = y_test.loc[X_test_pos.index]\n",
    "y_test_neg = y_test.loc[X_test_neg.index]\n",
    "\n",
    "X_train = X_train.drop(columns=[\"MI_12SL\"])\n",
    "X_test = X_test.drop(columns=[\"MI_12SL\"])\n",
    "\n",
    "# Extract MI_12SL predictions for only the positive subset\n",
    "y_12SL_pos = y_12SL.loc[X_test_pos.index]  # Original classifier's labels\n",
    "y_12SL_neg = y_12SL.loc[X_test_neg.index]\n",
    "\n",
    "\n",
    "# Train Explainable Boosting Machine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm = ExplainableBoostingClassifier(\n",
    "    learning_rate=0.2,\n",
    "    max_bins=255,\n",
    "    interactions=2,\n",
    "    min_samples_leaf=10,\n",
    "    n_jobs=-2\n",
    ")\n",
    "ebm.fit(X_train_pos, y_train_pos)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_pos = ebm.predict(X_test_pos)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_pos, y_pred_pos))\n",
    "# F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"F1 Score:\", f1_score(y_test_pos, y_pred_pos))\n",
    "\n",
    "# Show feature importance\n",
    "show(ebm.explain_global())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm = ExplainableBoostingClassifier(\n",
    "    learning_rate=0.001,\n",
    "    max_bins=512,\n",
    "    interactions=100,\n",
    "    min_samples_leaf=100,\n",
    "    early_stopping_rounds=50,\n",
    "    n_jobs=-2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "# Compute weights based on class distribution\n",
    "sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train_neg)\n",
    "\n",
    "# Train EBM with sample weights\n",
    "ebm.fit(X_train_neg, y_train_neg, sample_weight=sample_weights)\n",
    "\n",
    "#ebm.fit(X_train_neg, y_train_neg)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_neg = ebm.predict(X_test_neg)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_neg, y_pred_neg))\n",
    "# F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"F1 Score:\", f1_score(y_test_neg, y_pred_neg))\n",
    "\n",
    "# Show feature importance\n",
    "show(ebm.explain_global())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the search space\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True)\n",
    "    max_bins = trial.suggest_int(\"max_bins\", 64, 512)\n",
    "    interactions = trial.suggest_int(\"interactions\", 0, 5)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 2, 100)\n",
    "    max_leaves = trial.suggest_int(\"max_leaves\", 2, 64)\n",
    "    \n",
    "    ebm = ExplainableBoostingClassifier(\n",
    "        learning_rate=learning_rate,\n",
    "        max_bins=max_bins,\n",
    "        interactions=interactions,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_leaves=max_leaves,\n",
    "        n_jobs=-2\n",
    "    )\n",
    "    \n",
    "    ebm.fit(X_train_pos, y_train_pos)\n",
    "    y_pred = ebm.predict(X_test_pos)\n",
    "\n",
    "    return f1_score(y_test_pos, y_pred)\n",
    "\n",
    "# Run the study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "print(\"Best F1 score:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ebm = ExplainableBoostingClassifier(\n",
    "    **study.best_params,\n",
    "    n_jobs=-2\n",
    ")\n",
    "best_ebm.fit(X_train_pos, y_train_pos)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_pos, best_ebm.predict(X_test_pos)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
